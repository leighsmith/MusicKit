<!-- $Id$ -->
<chapter id="NoteListToScoreFile">
<title>From The Classical Software Synthesis Note-List to the
<productname>MusicKit</productname> Scorefile</title>

<para>This introduction to the <productname>MusicKit</productname>
Scorefile is aimed at people who are familiar with the note-list used
in &ldquo;classical&rdquo; software synthesis languages such as
<application>Music5</application>.  However, it should be useful to
others as well.  For brevity, we refer to the classical note-list as,
simply<emphasis> note-list</emphasis>, and the
<productname>MusicKit</productname> Scorefile as
<emphasis>scorefile</emphasis>.</para>

<para>The <emphasis role="bold">scorefile</emphasis> is part of the
<productname>MusicKit</productname>. The
<productname>MusicKit</productname> supports both real-time synthesis
and accelerated non-real-time synthesis using the built-in DSP and
sound hardware. (It also supports <acronym>MIDI</acronym> processing,
interactive applications, etc., but these do not concern us here.) The
<emphasis role="bold">scorefile</emphasis>, therefore, must be capable
of representing both event-based data, such as
<acronym>MIDI</acronym>, and compositional data, such as the classical
note-list. Many of its characteristics stem from this aim. </para>

<sect1 id="HardToRead">
<title>Classical Parameter Lists Can Be Hard To Read</title>

<para>Most note-lists represent notes in the form of pseudo-function
calls, where the function is a software instrument name and the
arguments are the note parameters.  For example: </para>

<programlisting>
guitar 0 2 440 3 F1;
</programlisting>

<para>Here <emphasis>guitar</emphasis> is the name of the software
instrument, 0 is the begin time, 2 is the duration, 440 is the
frequency, 3 is perhaps the FM index and <emphasis>F1</emphasis> is
the name of an envelope. The effect of this line in the note-list is
to create a note with the parameters given. </para>

<para>This is fine for very simple instruments with few parameters,
but it becomes terribly unwieldy for complex instruments with many
parameters. Notes like this are not uncommon: </para>

<programlisting>
guitar 0 2 440 3 F1 4 .1 432 0 0 0 .5423 1 55 F2 .11
       0 0 0 0 0 .44 0 0 0 880 F2 0 0 0;
</programlisting>

<para>Several notes in a row may have only a few small parameter
changes. But every parameter must be repeated: </para>

<programlisting>
guitar 0 2 440 3 F1 4 .1 332 0 0 0 .5423 1 55 F2 .11	
       0 0 0 0 0 .44 0 0 0 880 F2 0 0 0;  		
guitar 3 2 880 3 F1 4 .1 432 0 0 0 .6423 1 55 F2 .11 	
       0 0 0 0 0 .44 0 0 0 880 F2 0 0 0;  		
guitar 7 2 880 3 F1 4 .1 432 0 0 0 .5423 1 55 F2 .11
       0 0 0 0 0 .44 0 0 0 440 F2 0 0 0;  
</programlisting>

<para>Since the position of each number in the list determines the
parameter to which the number applies, all parameters must be supplied
on every note (clever ordering and defaulting of trailing parameters
makes this not strictly true, but does not solve the basic
problem.)</para>

</sect1>
<sect1 id="Keywords">
<title>Scorefiles Use Keywords To Make Order-Independent Parameter
Lists</title>

<para>Instead of ordered parameters, the <emphasis
role="bold">scorefile</emphasis> uses keywords to identify
parameters. Only the parameters that differ from the defaults need be
specified for a given note. Here's a parameter list for a <emphasis
role="bold">scorefile</emphasis> note: </para>

<programlisting>
freq:440 amp:.1 bearing:-45
</programlisting>

<para>The frequency parameter is set to 440, the amplitude parameter
is set to .1 and the bearing parameter (left/right panning) is set to
-45 (the left speaker).</para>

</sect1>
<sect1 id="Reorchestration">
<title>Keywords Make Reorchestration Easier</title>

<para>The note-list is difficult to reorchestrate, since different
synthesis instruments have different parameters, possibly in different
orders. With the <emphasis role="bold">scorefile</emphasis> approach,
this is not a problem. Parameters unrecognized by one instrument are
simply ignored. A new parameter keyword may be added to a <emphasis
role="bold">scorefile</emphasis> at will. Of course, it will have no
effect unless the program that reads the <emphasis
role="bold">scorefile</emphasis> is sensitive to that
parameter. </para>

<para><emphasis role="bold">Scorefile</emphasis> parameters can be
thought of as messages whose precise meaning depends on what
application or instrument responds to the message. Different
instruments can implement the same parameter in different ways.  For
example, a pseudo-wind instrument can interpret a crescendo to mean
&ldquo;blow harder&rdquo; while a pseudo-string instrument can
interpret it to mean &ldquo;move the bow faster and press
harder&rdquo;.</para>

</sect1>
<sect1 id="PartsMakeReorchestrationEasier">
<title>Parts Make Reorchestration Easier</title>

<para>In a classical note-list the first element in a note is a
&ldquo;hard-wired&rdquo; instrument name. To change which instrument
realizes a musical passage, every note in that passage must be
changed. In contrast, a <emphasis role="bold">scorefile</emphasis>
note begins with a <emphasis role="bold">part</emphasis>
specification.  A part is an abstract grouping of notes that are
realized in a similar manner, e.g. with the same software instrument.
Parts may contain chords and multiple polyphonic lines.</para>

<para>The mapping from part to software instrument is
&ldquo;soft-wired&rdquo;. The instrument may be specified in the
header of the <emphasis role="bold">scorefile</emphasis> as a
parameter of a special note called the <emphasis>part
info</emphasis>. Applications use the part info as a hint as to how to
orchestrate the music. Different applications may behave
differently. One application might ignore the software instrument
specification and play the score via <acronym>MIDI</acronym> on an
external synthesizer.</para>

<tip><para>The Common Music System by Heinrich Taube has an
analogous but subtly different notion of &ldquo;part&rdquo;.  A
<productname>MusicKit</productname> part is an ordered set of notes.
A Common Music part is a part of a Lisp program that creates that set
of notes. See the Common Music Manual [Taube], Introduction to Common
Music [Jaffe, Taube] and the document &ldquo;Creating Music with Common Music
and the <productname>MusicKit</productname>&rdquo;
[Jaffe,Taube]].</para></tip>

<para>Here's a sample <emphasis role="bold">scorefile</emphasis>
header. First we declare a part, then we give it a part info: </para>

<programlisting>
/* This is a comment. */ 		
part soprano;              /* Part declaration.  */ 	
soprano synthPatch:"Fm1vi" synthPatchCount:4 midiChan:3;
</programlisting>

<para>This specifies that the soprano part use a <emphasis
role="bold">synthPatch</emphasis> called &ldquo;Fm1vi&rdquo;. A synthPatch
is a <productname>MusicKit</productname> software instrument that runs
on the built-in DSP. In this case, the synthPatch is Fm1vi. This
string stands for &ldquo;frequency modulation with one modulator,
vibrato, and using an interpolating oscillator&rdquo;.</para>

<para>The parameter <emphasis role="bold">synthPatchCount</emphasis>
may optionally be supplied to provide allocation information. In this
case, we would like four synthpatches allocated to this part. If no such
parameter is included, allocation is handled dynamically and
automatically. </para>

<para>An application that plays the <emphasis
role="bold">scorefile</emphasis> on <acronym>MIDI</acronym> uses the
<emphasis role="bold">midiChan</emphasis> parameter to determine on
which <acronym>MIDI</acronym> channel to send the notes in the part.
</para>

</sect1>
<sect1 id="ACompleteScorefile">
<title>A Complete Scorefile</title>

<para>At this point, let's take a look at a complete simple <emphasis
role="bold">scorefile</emphasis>: </para>

<programlisting>
part soprano; 		
soprano synthPatch:"Fm1vi" synthPatchCount:4;	

/* BEGIN Specifies the end of the header and beginning of the body. */
BEGIN;
t 0; 		
soprano (2) freq:c4; 		
t 1; 		
soprano (2) freq:d4; 		
t +1; 		
soprano (2) freq:e4;
</programlisting>

<para>This plays three overlapping notes, each with a duration of 2.
The 2 is not given a parameter keyword. Instead it appears in a
special place surrounded by parentheses. The reason for this will be
explained later. Notice that unlike in the classical note-list, the
onset time appears outside of the note in a separate &ldquo;time
statement&rdquo;.  This allows chords to be more easily recognized
visually. </para>

<para>Time may be specified relatively or absolutely. In the example
above, the first two time statements specify absolute time, while the
third specifies relative time. A relative time statement advances time
from its previous value by the amount specified. Use of relative time
makes it easy to &ldquo;cut and paste&rdquo; sections from one
<emphasis role="bold">scorefile</emphasis> to another.  On the other
hand, use of absolute time makes it easy to know where you are in a
<emphasis role="bold">scorefile</emphasis>. Since both are handy, we
provide both.</para>

<para>Durations and times are in beats, interpreted relative to a
tempo. The tempo is specified in a special header note that contains
parameters that affect the whole score. This note is called a
&ldquo;score info&rdquo; or simply 
<emphasis role="bold">info</emphasis>:</para>

<programlisting>
info samplingRate:44100 tempo:84;
</programlisting>
</sect1>
<sect1 id="NotesOfVariousTypes">
<title>Scorefiles Have Notes of Various Types</title>

<para>Notes in most software synthesis languages always have a
duration.  However, when responding to real-time events, the duration
is not necessarily known. When a performer presses his finger on a
klavier-style keyboard, the computer must begin a note now but has no
idea when the performer will lift his finger from the
keyboard. <acronym>MIDI</acronym> breaks notes into on/off
pairs. <emphasis role="bold">Scorefiles</emphasis> represent both the
<acronym>MIDI</acronym>-style and the note-list-style of note by
including a note type in the note specification. The note types are
<emphasis role="bold">noteOn</emphasis>, <emphasis
role="bold">noteOff</emphasis>, <emphasis
role="bold">noteDur</emphasis>, <emphasis
role="bold">noteUpdate</emphasis> and <emphasis
role="bold">mute</emphasis>. NoteOn is the start of a musical note,
similar to the <acronym>MIDI</acronym> noteOn.  NoteOff is the end of
a musical note or, more precisely, the point when the performer lifts
his finger from the key, triggering the beginning of the final portion
of the envelopes. NoteDur is a note with a duration. NoteUpdates are
explained later. Mutes are notes that make no sound, used for a
variety of purposes such as <acronym>MIDI</acronym> system exclusive
messages.</para>

<para>The following example shows three notes, a noteOn, a noteOff and
a noteDur:</para>

<programlisting>
guitar (noteOn, 4) freq:c4;
t +2; 		
guitar (noteOff, 4); 		
t +2; 		
guitar (2) freq:c5;
</programlisting>

<para>We now see why the duration parameter does not have a
label. Supplying a duration in place of the note type identifies the
note as a noteDur.</para>

<para>The number 4 following the note type in the first two notes is a
<emphasis role="bold">noteTag</emphasis>. Since noteOns and noteOffs
are only &ldquo;half a note&rdquo; as it were, there needs to be some way to
match them up. We could simply say that a noteOff matches the most
recent noteOn played by the same part. But then it would not be
possible to do chords or polyphony in a single
part. <acronym>MIDI</acronym> handles the situation by using the
<acronym>MIDI</acronym> channel (in mono mode) or a combination of the
key number and channel (in poly mode). However,
<acronym>MIDI</acronym>'s approach is problematic in many cases. For
example, in a general computer music system, we do not want to be
limited to 88 discrete pitches. We would like to be able to specify
slight retuning without disturbing the matching of a noteOn and a
noteOff. Therefore, we prefer to avoid use of key number or frequency
to identify notes.</para>

<para>As mentioned above, <emphasis role="bold">scorefile</emphasis>s
use noteTags to match noteOns and noteOffs. NoteTag matching does not
depened on frequency at all. Therefore, there's no need to repeat the
freq: parameter in the noteOff. </para>

<para>NoteTags also serve another significant purpose. They make
phrase-level structure possible.</para>
</sect1>
<sect1 id="PhraseStructure">
<title>Phrase Structure</title>

<para>In the classical note-list, each note is a separate entity,
unrelated to any other notes. Legato effects must be achieved using
overlapping notes or by embedding information in the
parameters.</para>

<para><emphasis role="bold">Scorefile</emphasis> noteTags can
represent phrase structure. In addition to their function of matching
noteOns and noteOffs, noteTags associate notes of a given phrase
within a single part.  Several noteOns (or noteDurs) with the same
noteTag are interpreted as rearticulations within a single melody. No
overlap results.  Unlike in <acronym>MIDI</acronym>, <emphasis
role="bold">scorefile</emphasis> noteOns do not have to be each
matched with a noteOff.  Any number of noteOns on the same noteTag are
matched by a single noteOff.  (The <productname>MusicKit</productname>
does automatic conversion between <emphasis
role="bold">scorefile</emphasis> and <acronym>MIDI</acronym> semantics
when it reads or writes <acronym>MIDI</acronym> bytes or a
<acronym>MIDI</acronym> file.) To solve the mixing problem, the
<productname>MusicKit</productname> automatically remaps NoteTags when
it reads a <emphasis role="bold">scorefile</emphasis>.  This assures
that note tags in several files will not collide, even if the files
share noteTags.</para>

<para>Here is a <emphasis role="bold">scorefile</emphasis> fragment
that produces a single line of 3 notes.</para>

<example id="ex1"
<title>Example 1</title>
<programlisting>
guitar (noteOn,1) freq:c4; 		
t +.1; 		
guitar (noteOn,1) freq:d4; 		
t +.2; 		
guitar (noteOn,1) freq:e4; 		
t +.2; 		
guitar (noteOff,1);
</programlisting>
</example>

<para>In contrast, the next example produces 3 overlapping notes:</para>

<example id="ex2">
<title>Example 2</title>
<programlisting>
guitar (2) freq:c4; 		
t +.1; 		
guitar (2) freq:d4; 		
t +.2; 		
guitar (.2) freq:e4;
</programlisting>
</example>

<para>If noteTags are added to <xref linkend="ex2">, it behaves like
<xref linkend="ex1">, again producing a single line of 3 notes. The
durations, if they are longer than the time between notes with the
same tag, are ignored.
</para>

<example id="ex3">
<title>Example 3</title>
<programlisting>
guitar (2,1) freq:c4; 		
t +.1; 		
guitar (2,1) freq:d4; 		
t +.2; 		
guitar (.2,1) freq:e4;
</programlisting>
</example>

<para>Of course, you can combine the two approaches. <xref linkend="ex4">
produces a line of 3 notes and 3 overlapping notes.</para>

<example id="ex4">
<title>Example 4</title>
<programlisting>
guitar (noteOn,1) freq:c4; 		
guitar (2) freq:c5;
t +.1;
guitar (2) freq:d4;
guitar (noteOn,1) freq:d5;
t +.2;
guitar (.2) freq:e4;
guitar (noteOn,1) freq:e5; 		
t +.2;
guitar (noteOff,1);
</programlisting>
</example>

<para>As a final example, we add a second 2-note melody by using a
different noteTag: </para>

<example id="ex5">
<title>Example 5</title>
<programlisting>
guitar (noteOn,1) freq:c4; 		
guitar (2) freq:c5; 		
guitar (noteOn,2) freq:g5; 		
t +.1;
guitar (2) freq:d4; 		
guitar (noteOn,1) freq:d5; 		
t +.2; 		
guitar (.2) freq:e4; 		
guitar (noteOn,1) freq:e5; 		
guitar (noteOn,2) freq:g5; 		
t +.2; 		
guitar (noteOff,1); 		
guitar (noteOff,2);
</programlisting>
</example>

</sect1>
<sect1 id="EventBasedAndEnvelopeBasedControl">
<title>Scorefiles Support Both Event-Based and Envelope-Based
Continuous Control</title>

<para>A note cannot be addressed from the classical note-list once the
note has begun. It is not possible, for example, to alter the
parameter of a note once it has started playing. This means all
continuous change must be built into the instrument and specified in
advance via envelopes.  But in a real-time situation, such as
<acronym>MIDI</acronym> or any interactive application, the future is
not known and cannot be predicted. </para>

<para><acronym>MIDI</acronym> solves the problem with its special
&ldquo;continous controllers&rdquo; that must be interpreted by the
synthesizer. The <emphasis role="bold">scorefile</emphasis> is even
more flexible. It allows any parameter of a note that's already
playing to be changed at any time, simply by specifying the noteType
as <emphasis role="bold">noteUpdate</emphasis> and giving the
appropriate noteTag.  In this example the note goes sharp and its
amplitude is increased: </para>

<example id="ex6">
<title>Example 6</title>
<programlisting>
guitar (noteOn,1) freq:c4 amp:.1 		
t +2; 		
guitar (noteUpdate,1) amp:.3 freq:cs4; 		
t +2;		
guitar (noteOff,1); 	
</programlisting>
</example>

<para><emphasis role="bold">Scorefiles</emphasis> can also represent
envelopes. Envelopes are defined as (X,Y) pairs (with an optional Z
parameter that represents &ldquo;smoothing&rdquo;).</para>

<para>For example here's an envelope definition:</para>

<programlisting>
envelope martele = [(0,0)(.1,1)(.6,.2)|(1.0,0)];
</programlisting>

<para>The X values are in seconds, independent of the tempo. The
portion up to the stick point (represented as a vertical bar
&ldquo;|&rdquo;) is called the &ldquo;attack portion&rdquo;. Tempo
variations do not cause attack times to be distorted. The reasoning
here is that the attack of an acoustic instrument, such as a
xylophone, is invariant with respect to tempo.</para>

<para>The portion after the vertical bar is called the &ldquo;decay
portion&rdquo;. There is no absolute limit to the number of points in
an envelope. Both the attack and the decay portions may have any
number of points.</para>

<para>The envelope progresses as follows: It proceeds until the stick
point (at .6 seconds after the onset, with a Y value of .2) and then
waits until the noteOff (or, for a noteDur, the end of the
duration). Then it proceeds with the final segment(s). For example, if
the note has a duration of 4, the final segment begins after 4 beats
and the decay takes .4 seconds.  Alternatively, an optional attack
time and decay parameter may be supplied for each envelope in a
note. These scale the X values in the envelope definition. For
example, if <emphasis>martele</emphasis> is used as an amplitude
envelope and <emphasis role="bold">ampAtt</emphasis>, the amplitude
attack parameter, is equal to .1, the resulting envelope X values will
be 0, .01, .06. The release portion may similarly be scaled. Here is
an example of a note that uses the <emphasis
role="bold">ampAtt</emphasis> and <emphasis
role="bold">ampRel</emphasis> parameters. </para>

<programlisting>
weaslePhone (4) amp:.3 ampEnv:martele ampAtt:.1 ampRel:6.0;
</programlisting>

<para>The <emphasis role="bold">amp</emphasis> parameter does scaling
on the envelope values. Actually, <emphasis role="bold">amp</emphasis>
is really a synonym for <emphasis role="bold">amp1</emphasis>, the
value of the amplitude when the envelope is at 1.0. There is also an
optional parameter <emphasis role="bold">amp0</emphasis>, that
signifies the value of the amplitude when the envelope is at 0. This
convention is followed uniformly for all parameters that take
envelopes. For example, a frequency envelopes parameters are <emphasis
role="bold">freq0</emphasis>,<emphasis role="bold">
freq1</emphasis>,<emphasis role="bold"> freqAtt</emphasis>,<emphasis
role="bold"> freqRel</emphasis>,<emphasis role="bold"></emphasis> and
<emphasis role="bold">freqEnv</emphasis>.</para>

</sect1>
<sect1 id="NoteUpdatesWithoutTags">
<title>NoteUpdates Without Tags Set Defaults</title>

<para>If a noteUpdate has no tag, it applies to all currently playing
notes of the part in which it appears. It also becomes the default for
future notes. This mechanism can be used to provide
&ldquo;voicings&rdquo; that periodically change.</para>

<example id="ex7">
<title>Example 7</title>
<programlisting>
singer (noteUpdate) waveLen:128.000 svibAmp0:.003 	
           svibAmp1:.011 rvibAmp:.006 bearing:.000;	 		
t 0.800; 		
singer (2) freq0:466.164 freq1:466.164 freqEnv:frqFn0 amp:-12dB
           ampEnv:ampFn1 waveform0:"0SU" waveform1:"SU"	
           waveformEnv:intFn0 freqAtt:.200 waveformAtt:.200
           svibFreq0:3.125 svibFreq1:4.630;	
</programlisting>
</example>

</sect1>
<sect1 id="VariousParameterTypes">
<title>Scorefiles Support Various Parameter Types</title>

<para><xref linkend="ex7"> also illustrates that a parameter may be a
number of types: a string, a floating point number, an integer, an
envelope, a wavetable (see below), or a type defined by the
application that reads the <emphasis
role="bold">scorefile</emphasis>.</para>

<para>WaveTables may be represented in either the frequency or the
time domain. In the frequency domain, they are represented as pairs of
the form {harmonic number,relative amplitude}.  An optional third
element gives the phase of the component. For example, here is a
clarinet-like waveTable, containing only odd harmonics: </para>

<programlisting>
waveTable clarinet = [{1,1}{3,.5}{7,.2},{9,.05}];
</programlisting>

<para>In the time domain, waveTables are represented by specifying the
soundfile that holds the samples:</para>

<programlisting>
waveTable sampledClarinet = [{"onePeriodOfAClarinet.snd"}];
</programlisting>

<para>It is usually preferable to specify a waveTable in the frequency
domain, since it is more easily transposable.</para>

<tip><para>Note that waveTables use curly braces rather than
parentheses (This is needed because envelopes and waveTables may
appear as unnamed data. The use of a different syntax allows the
parser to differentiate unnamed waveTables from unnamed envelopes).
</para>
</tip>

</sect1>
<sect1 id="SimpleLanguageConstructs">
<title>The <productname>MusicKit</productname> Allows Simple Language
Constructs to Appear in a Scorefile</title>

<para>The <productname>MusicKit</productname> can read an extended
<emphasis role="bold">scorefile</emphasis> format called
<emphasis>ScoreFile</emphasis> that is actually a simple language
supporting variables, expressions and operators. While
<emphasis>ScoreFile</emphasis> is not intended as a means of entering
musical data, it is useful for fine-tuning or making other minor
modifications to a piece.</para>

<para>As a final example, here is a
<productname>MusicKit</productname> <emphasis
role="bold">scorefile</emphasis> with some
<emphasis>ScoreFile</emphasis> constructs included:</para>

<programlisting>
info tempo:72;
part bell; 
bell synthPatch:"Fm1i" synthPatchCount:9; 

envelope ampFun =  [(0,0)(.005,0dB)(10,-40dB)|(14,0.0)(15,0)];
envelope freqFun =  [(0,1)(.005,bf4/a4)(.01,1)(10,1)|(14,.9,2)];
envelope indxFun =  [(0,2)(.005,1)(10,0,.3)|(14,0.0)];

waveTable wave1  = [{1,1}{3,.1}]; 

BEGIN;
bell (noteUpdate) waveform:wave1 m1Ratio:3.4
     m1Ind1:.4 amp:0.2 ampEnv:ampFun freqEnv:freqFun 	
     m1IndEnv:indxFun;

t .001;
bell (4.5) freq:c7 bearing:-45 + ran; /* ran returns a random number */
bell (4.5) freq:c7+4.5 bearing:0;
t +.1;
bell (4.4) freq:b6 bearing:-35 + ran;
bell (4.4) freq:b6+4.1 bearing:10;
t .2;
bell (4.3) freq:g6 bearing:-25;
bell (4.3) freq:g6+4.8 bearing:20;
t .3;
bell (4.2) freq:f6 bearing:-15;
bell (4.2) freq:f6+5.5 bearing:30;
t .4;
print "Last note coming up. Time is ",t,"\n"; 
bell (4.1) freq:d6 bearing:45;
END;	
</programlisting>

</sect1>
<sect1 id="NoteListToScorefileSummary">
<title>Summary</title>

<para>The <productname>MusicKit</productname> <emphasis
role="bold">scorefile</emphasis> has its roots in both the classical
note-list and <acronym>MIDI</acronym>.  The scorefile makes it
possible to express the generality of software synthesis note-lists as
well as the performance nuance and control characteristics of
<acronym>MIDI</acronym>.</para>
</sect1>

<sect1 id="ScoreFileAcknowledgements">
<title>Acknowledgements</title>

<para>Julius Smith, Bill Schottstaedt, and Doug Fulton made
substantial contributions to the <emphasis
role="bold">scorefile</emphasis> and <emphasis>ScoreFile</emphasis>
designs.</para>
</sect1>
</chapter>
